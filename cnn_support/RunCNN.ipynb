{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5560bc8-607d-416e-b789-7965110a4ade",
   "metadata": {},
   "source": [
    "# Run a suite of CNN models and apply them to test data sets and whole tiles\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ef073a-e4b5-480e-8332-0cc63d2631b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import run_cnn\n",
    "\n",
    "train = run_cnn.TrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a86f72-71f1-44ce-8674-1e1d633d9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Paths to the feature (LiDAR), response (manually labelled buildings) and boundary files, and to\n",
    "the directory where the output will be written\n",
    "\"\"\"\n",
    "\n",
    "base_path = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/'\n",
    "boundary_path = base_path+'labeled_region_boundaries/'\n",
    "feature_path = base_path+'labeled_region_features/'\n",
    "response_path = base_path+'labeled_region_buildings2/'\n",
    "\n",
    "paths = {'boundary': boundary_path, 'responses': response_path, 'features': feature_path}\n",
    "\n",
    "bfgn_output_path = base_path+'bfgn_output_buildings2/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d6dc6d-4f02-4efd-8fe9-e4e511ca0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the training and test sets\n",
    "\"\"\"\n",
    "\n",
    "training_sets = {'HBLower': 'HBLower',\\\n",
    "                           'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'CCTrees': 'tile024_10000_4375',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8082fa-e46b-41e0-a827-0d7a97d2dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'SKona_A': 'SKona_TestA',\\\n",
    "                       'SKona_B': 'SKona_TestB',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'KonaMauka': 'KonaMauka'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c34fca-2145-47fe-b0a6-264f774274ae",
   "metadata": {},
   "source": [
    "## Run the model suite\n",
    "\n",
    "The test datasets and model parameters vary like this:\n",
    "\n",
    "Data types:\n",
    "- 1m DSM\n",
    "- 1m eigenvalues, all 4 bands\n",
    "- 1m hillshade\n",
    "\n",
    "Training data:\n",
    "- all available labelled training regions\n",
    "\n",
    "Window sizes:\n",
    "- 16, 32, 64 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b2bedb-5b8c-4fea-a19c-d1fa71e72fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 parameter combinations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_types = ['hires_surface', 'eigen4', 'hillshade']\n",
    "training_set = []\n",
    "for _ in range(len(data_types)):\n",
    "    training_set.append(['HBLower', 'HOVE1', 'MIL1', 'CC1', 'Hamakua', 'KParadise', 'CCTrees', 'WAI1', 'KK1',\\\n",
    "                        'Waimea'])\n",
    "\n",
    "training_data = train.create_training_lists(paths, training_sets, training_set)\n",
    "\n",
    "permutations = dict.fromkeys(['boundary_files', 'feature_files', 'response_files', 'window_radius',\\\n",
    "                              'loss_window_radius']) \n",
    "\n",
    "#This gives 1 set of training regions, 3 window sizes (w/ appropriate loss_window_radius)\n",
    "parameter_combos = [(training_data[0][0], training_data[0][1], training_data[0][2], 16, 8),\\\n",
    "                    (training_data[0][0], training_data[0][1], training_data[0][2], 32, 16),\\\n",
    "                    (training_data[0][0], training_data[0][1], training_data[0][2], 64, 32)]\n",
    "\n",
    "#This adds the different data types - DSM, eigenvals, hillshade\n",
    "for kind in data_types[1:]:\n",
    "    for data in parameter_combos[:3]:\n",
    "        new = [[x[0].replace('hires_surface', kind)] for x in data[1]]\n",
    "    parameter_combos.extend([(training_data[0][0], new, training_data[0][2], 16, 8),\\\n",
    "                    (training_data[0][0], new, training_data[0][2], 32, 16),\\\n",
    "                    (training_data[0][0], new, training_data[0][2], 64, 32)])\n",
    "\n",
    "print(f\"There are {len(parameter_combos)} parameter combinations\")\n",
    "            \n",
    "iteration_data = {} \n",
    "iteration_data['permutations'] = permutations\n",
    "iteration_data['parameter_combos'] = parameter_combos\n",
    "iteration_data['nicknames'] = ['hires_surface_16', 'eigen4_16', 'hillshade_16', 'hires_surface_32', 'eigen4_32',\\\n",
    "                               'hillshade_32', 'hires_surface_64', 'eigen4_64', 'hillshade_64']\n",
    "iteration_data['out_path'] = bfgn_output_path+'model_runs/'\n",
    "iteration_data['data_types'] = data_types\n",
    "\n",
    "model_runs = run_cnn.Loops(iteration_data, settings_file='settings_buildings.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5570ad51-6b7d-4ff3-a0ee-ea4a0863968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================\n",
      "Working on parameter combination #0:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_0/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #1:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_1/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #2:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_2/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #3:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_3/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #4:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_4/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #5:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_5/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #6:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_6/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #7:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_7/model.h5 exists; nothing to do here\n",
      "\n",
      "===================================================\n",
      "Working on parameter combination #8:\n",
      "\n",
      "***Model /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/combo_8/model.h5 exists; nothing to do here\n",
      "CPU times: user 12.3 ms, sys: 11.7 ms, total: 24 ms\n",
      "Wall time: 330 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_runs.loop_over_configs(use_existing=True, rebuild_data=True, fit_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f2d59-a495-4e72-9e69-fd40d9a38335",
   "metadata": {},
   "source": [
    "## Apply the models to the test regions and the whole (trimmed) tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54312ef4-52e2-4ca1-a26e-082dcf5a597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The test regions\n",
    "\"\"\"\n",
    "\n",
    "#set to False if applied model files don't exist or we need to update them\n",
    "use_existing = True\n",
    "\n",
    "#find the paths to the saved model files, one for each parameter combo\n",
    "model_paths = sorted(glob.glob(model_runs.out_path+'combo_*'))\n",
    "\n",
    "#for each of the parameter combinations\n",
    "for model_dir, combo in zip(model_paths, parameter_combos):\n",
    "    config_file = f'{model_dir}/config.yaml'\n",
    "\n",
    "    #for each of the test regions\n",
    "    for idx, test_data in enumerate(test_sets.keys()):\n",
    "        \n",
    "        #name the appropriate kind of data for this parameter combo\n",
    "        #(e.g. parameter combo 0 was trained on 1m DSM))\n",
    "        for kind in data_types:\n",
    "            if kind in combo[1][idx][0].split('/')[-1]:\n",
    "                replace_with = kind\n",
    "                \n",
    "        #name the input data file, the applied model file, the file to be used as a \n",
    "        #template for interpolating the applied model to 2m, and the interpolated model\n",
    "        application_data = f'{feature_path}{test_sets[test_data]}_{replace_with}.tif'\n",
    "        outfile = f'{model_dir}/applied_model_{test_data}'\n",
    "        \n",
    "        #if there's isn't already a suitable applied model file, create it\n",
    "        if use_existing:\n",
    "            if not os.path.isfile(outfile+'.tif'):\n",
    "                model_runs.apply_model(config_file, application_data, outfile)\n",
    "        else:\n",
    "            model_runs.apply_model(config_file, application_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57661d02-caa7-4bd4-b80c-d3dfd75dff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The training regions - applied models won't be used for calculating any CNN model performance stats, but will be used\n",
    "for \n",
    "\"\"\"\n",
    "\n",
    "use_existing = True\n",
    "\n",
    "model_paths = sorted(glob.glob(model_runs.out_path+'combo_*'))\n",
    "\n",
    "for model_dir, combo in zip(model_paths, parameter_combos):\n",
    "    config_file = f'{model_dir}/config.yaml'\n",
    "    for idx, data in enumerate(training_sets.keys()):\n",
    "        for kind in data_types:\n",
    "            if kind in combo[1][idx][0].split('/')[-1]:\n",
    "                replace_with = kind\n",
    "\n",
    "        application_data = f'{feature_path}{training_sets[data]}_{replace_with}.tif'\n",
    "        outfile = f'{model_dir}/applied_model_{data}'\n",
    "\n",
    "        if use_existing:\n",
    "            if not os.path.isfile(outfile+'.tif'):\n",
    "                model_runs.apply_model(config_file, application_data, outfile)\n",
    "        else:\n",
    "            model_runs.apply_model(config_file, application_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43265936-6bcc-4682-9d35-9dfaf4dc3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Tiles\n",
    "\"\"\"\n",
    "\n",
    "tiles = ['tile024', 'tile025', 'tile030', 'tile031', 'tile008', 'tile009', 'tile014', 'tile015',\\\n",
    "         'tile016', 'tile021', 'tile022', 'tile007', 'tile012',  'tile013', 'tile018', 'tile019', 'tile020']\n",
    "\n",
    "#set to False if applied model files don't exist or we need to update them\n",
    "use_existing = True\n",
    "\n",
    "#find the paths to the saved model files, one for each parameter combo\n",
    "model_paths = sorted(glob.glob(model_runs.out_path+'combo_*'))\n",
    "\n",
    "for tile in tiles:\n",
    "    n = 0\n",
    "    #for each parameter combination\n",
    "    for model_dir, combo in zip(model_paths, parameter_combos):\n",
    "        \n",
    "        config_file = f'{model_dir}/config.yaml'\n",
    "\n",
    "        #set up the name of the file the model will be applied to\n",
    "        if 'hires_surface' in combo[1][0][0]:\n",
    "            path = '/data/gdcsdata/HawaiiMapping/Full_Backfilled_Tiles/'\n",
    "            suffix = 'backfilled_surface_1mres.tif'\n",
    "            application_data = f'{path}{tile}/{tile}_{suffix}'\n",
    "        elif 'eigen4' in combo[1][0][0]:\n",
    "            path = '/data/gdcsdata/HawaiiMapping/Full_Backfilled_Tiles/'\n",
    "            suffix = 'backfilled_surface_1mres_eigen4band_5mwind.tif'\n",
    "            application_data = f'{path}{tile}/{tile}_{suffix}'\n",
    "        elif 'hillshade' in combo[1][0][0]:\n",
    "            suffix = 'hillshade.tif'\n",
    "            application_data = f'{feature_path}{tile}_{suffix}'\n",
    "\n",
    "        outfile = f'{model_dir}/applied_model_{tile}'\n",
    "\n",
    "        if use_existing:\n",
    "            if not os.path.isfile(outfile+'.tif'):\n",
    "                model_runs.apply_model(config_file, application_data, outfile)\n",
    "        else:\n",
    "            model_runs.apply_model(config_file, application_data, outfile)\n",
    "        \n",
    "        n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfgn-gpu",
   "language": "python",
   "name": "bfgn-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

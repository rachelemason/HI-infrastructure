{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cdfd0c-7b58-4d59-be45-8992e15fc780",
   "metadata": {},
   "source": [
    "This notebook takes the training and test region probability maps that were created in RunCNN.ipynb, uses them along with imaging spectroscopy and the canopy height maps to train a gradient boosting trees model, produces updated maps, then applies vector operations to further refin the maps. The trained models are then applied to the entire ~3000 sq km study region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bc036-f2ff-4a44-8c49-bd8cba4c371f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508b5c48-8a15-45a4-87cd-8a98ba35b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remason2/.conda/envs/xgboost/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import run_xgb\n",
    "import apply\n",
    "\n",
    "base_path = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/'\n",
    "analysis_path = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/analysis/'\n",
    "model_paths = sorted(glob.glob(base_path+'combo_*'))\n",
    "\n",
    "#Bands that will be excluded from reflectance dataset\n",
    "bad_bands = []\n",
    "for item in [range(0,5), range(94, 117), range(142, 179), [211, 212, 213]]:\n",
    "    bad_bands.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66689593-27a3-4f9d-95bb-e310946166e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test datasets are labelled datasets not involved in training, which will be used for assessing map\n",
    "quality (calculating performance stats). Training datasets will not be used for stats, but will be\n",
    "used in modelling that removes false positive building detections.\n",
    "\n",
    "The contents of the test_sets and training_sets variables must match those in RunModels.ipynb.\n",
    "\"\"\"\n",
    "\n",
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'SKona_A': 'SKona_TestA',\\\n",
    "                       'SKona_B': 'SKona_TestB',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'KonaMauka': 'KonaMauka'}\n",
    "\n",
    "training_sets = {'HBLower': 'HBLower',\\\n",
    "                           'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'CCTrees': 'tile024_10000_4375',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea'}\n",
    "\n",
    "all_labelled_data = {**test_sets, **training_sets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3731cbd-4b73-469b-8a3f-5b1725b6a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = performance.Utils(all_labelled_data)\n",
    "\n",
    "manips = performance.MapManips(model_output_root=base_path, all_labelled_data=all_labelled_data)\n",
    "\n",
    "stats = performance.Stats(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                          all_labelled_data=all_labelled_data,\\\n",
    "                          analysis_path=analysis_path)\n",
    "\n",
    "ensemble = performance.Ensemble(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                                ensemble_path=base_path+'ensembles/',\\\n",
    "                                all_labelled_data=all_labelled_data)\n",
    "\n",
    "evalz = performance.Evaluate(model_output_root=base_path, training_sets=training_sets,\\\n",
    "                             all_labelled_data=all_labelled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d3d04-761b-4fe4-a81c-aaa626b3d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping (files exist)\n",
    "utils.remove_small_buildings(outpath='buildings2/', minsize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2d537-8731-4804-ad9e-4fadc20cc397",
   "metadata": {},
   "source": [
    "## Make ensemble CNN probability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebea23-aae2-4112-a15e-137996b0cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    ensemble.average_probabilities(model_nums=[0, 1, 2, 3, 4, 5, 6, 7, 8], model_kind='CNN',\\\n",
    "                                   region=region, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e804fd-18ba-4691-832a-62b9c7c7b08e",
   "metadata": {},
   "source": [
    "Now show probability distributions for correctly-and incorrectly-classified pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb7087-7f8c-4d95-bb49-8b4fae7afef5",
   "metadata": {},
   "source": [
    "## Convert probability maps to binary building/not-building maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f490c-0719-40cb-ae72-6e43de776f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    applied_model = f'{base_path}ensembles/mean_probability_{region}.tif'\n",
    "    outfile = f'{base_path}ensembles/threshold_{region}.tif'\n",
    "    manips.probabilities_to_classes(applied_model, outfile, 0.5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f63b0b-48e4-4057-bd7b-c878b11f0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "What is recall for building pixels when we classify the probability maps as prob. >0.5 --> building,\n",
    "prob < 0.5 --> not-building?\n",
    "\"\"\"\n",
    "\n",
    "statsfile = f'{analysis_path}cnn_classified.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    cnn_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    cnn_stats['class'] = stats.raster_stats(model_dir, map_kind=f'threshold', regions=test_sets)\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(cnn_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        cnn_stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfdb91-463f-478d-b9f7-68b1e334563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.plot_raster_stats(cnn_stats, plot_file='cnn_stats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77520f-819f-488a-b08d-1a880f00346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.display_raster_stats(cnn_stats['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e808074-44fe-48f9-97d1-84cd29add3e2",
   "metadata": {},
   "source": [
    "## Reclassify building candidate pixels using a gradient boosting model\n",
    "\n",
    "We'll try a few different versions of the training dataset\n",
    "\n",
    "1. Brightness-normalized, best guess at what would make a good training set\n",
    "1. Not brightness-normalized, same training set\n",
    "    - Seemed like this put lower probability on building pixles, but assigned non-zero probability to more of them. Could be a good thing to include in an ensemble.\n",
    "1. Maybe also 'tied' at some other wavelength?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac74be7-8403-4949-b86a-43c7448053d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\"\"\"\n",
    "Create 2m-resolution versions of the LiDAR+CNN-based maps\n",
    "\"\"\"\n",
    "\n",
    "model_dir = f'{base_path}ensembles/'\n",
    "feature_dir = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/labeled_region_features/'\n",
    "\n",
    "for region, name in all_labelled_data.items():\n",
    "    in_file = f'{model_dir}mean_probability_{region}.tif'\n",
    "    out_file = f'{model_dir}{region}_lores_model.tif'\n",
    "    template = f'{feature_dir}{name}_tch.tif'\n",
    "    utils.resample_raster(in_file, out_file, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ca980-d3e8-4e01-b8c2-4c5689cb4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvars = {'refl': [n for n in range(214) if n not in bad_bands], 'lores_model': ['model_prob'],\\\n",
    "         'tch': ['tch']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680419b-79b1-4788-8cc3-7680a46ecd20",
   "metadata": {},
   "source": [
    "### First run: Brightness normalization, best-guess training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03035e-6362-4df3-be17-e20a5817c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define how this run will be executed\n",
    "\"\"\"\n",
    "\n",
    "#TODO: these should be class attributes?\n",
    "run_id = 'run1'\n",
    "brightness_norm = True\n",
    "n_iter = 10\n",
    "\n",
    "training_sets = {'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea',\\\n",
    "                           'HBLower': 'HBLower',\\\n",
    "                           'SKona_A': 'SKona_TestA',\\\n",
    "                           'KonaMauka': 'KonaMauka',\\\n",
    "                           'CCTrees': 'tile024_10000_4375'}\n",
    "\n",
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'SKona_B': 'SKona_TestB'}\n",
    "\n",
    "all_labelled_data = {**training_sets, **test_sets}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd270e-c93b-493c-b610-410d1b61a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize classes\n",
    "\"\"\"\n",
    "\n",
    "utils = performance.Utils(all_labelled_data)\n",
    "\n",
    "manips = performance.MapManips(model_output_root=base_path,\\\n",
    "                               all_labelled_data=all_labelled_data)\n",
    "\n",
    "evalz = performance.Evaluate(model_output_root=base_path, training_sets=training_sets,\\\n",
    "                             all_labelled_data=all_labelled_data)\n",
    "\n",
    "stats = performance.Stats(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                          all_labelled_data=all_labelled_data,\\\n",
    "                          analysis_path=analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f56da-1a48-4e28-a319-186b5a4c7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Create the dataset to which the GB model will be fit. This contains all pixels from the training data sets, minus\n",
    "those for which there is no spectroscopy data.\n",
    "\"\"\"\n",
    "\n",
    "use_existing = True\n",
    "\n",
    "if use_existing:\n",
    "\n",
    "    with open(f'{model_dir}X_{run_id}.pkl', \"rb\") as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(f'{model_dir}y_{run_id}.pkl', \"rb\") as f:\n",
    "        y = pickle.load(f)\n",
    "else:\n",
    "    X, y = evalz.get_vars_from_rasters(xvars=xvars, bad_bands=bad_bands, mask_shade=True,\\\n",
    "                                       bnorm=brightness_norm, model_dir=model_dir, run_id=run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571bf007-39ea-49f4-9dcc-6c4153f80c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Classify all pixels using XGBOOST\n",
    "\"\"\"\n",
    "\n",
    "use_existing = True\n",
    "gb_file = f'{model_dir}gb_{run_id}.pkl'\n",
    "\n",
    "if use_existing:\n",
    "    with open(gb_file, \"rb\") as f:\n",
    "        gb = pickle.load(f)\n",
    "else:\n",
    "    gb = evalz.ml_classify(X, y, n_iter=n_iter, scoring='recall', save_to=gb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89781a50-eab0-4f7f-b9d7-490076870a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#X and y split into training and test sets by ml_classify\n",
    "train_test_file = f'{model_dir}train_test_{run_id}.pkl'\n",
    "\n",
    "#the file the Shapley values will be written to\n",
    "shap_file = f'/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/for_figures/shap_{run_id}.pkl'\n",
    "\n",
    "evalz.ml_metrics(gb, xvars, xy_file=train_test_file, save_to=shap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47beacb-f713-4d8b-862e-96a65c1435d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "out_prefix = f'{base_path}ensembles/gb_prob_{run_id}'\n",
    "manips.gb_prob_to_raster(gb, xvars=xvars, bad_bands=bad_bands, out_prefix=out_prefix,\\\n",
    "                                   model_dir=model_dir, bnorm=brightness_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd75c4-54fc-4e9d-9dbe-96eda4687172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "\"\"\"\n",
    "Classify into binary maps using a (low) threshold\n",
    "\"\"\"\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    applied_model = f'{base_path}ensembles/gb_prob_{run_id}_{region}.tif'\n",
    "    outfile = f'{base_path}ensembles/gb_class_{run_id}_{region}.tif'\n",
    "    manips.probabilities_to_classes(applied_model, outfile, 0.2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe20c0-69a7-4e62-adae-955eba471252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "statsfile = f'{analysis_path}{run_id}_test_sets.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    gb_test_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    gb_test_stats['XGB classified'] = stats.raster_stats(model_dir, map_kind=f'gb_class_{run_id}',\\\n",
    "                                                         regions=test_sets, resolution='lores_')\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(gb_test_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        gb_test_stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ba6f8-0387-4180-a877-855e5d0e8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.plot_raster_stats(gb_test_stats, plot_file=f'{run_id}_test_stats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ea4d0-74e6-4a79-9385-af5a1bf9d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.display_raster_stats(gb_test_stats['XGB classified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb6191-17bf-408f-a96a-db6f10fbf118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Training stats might be affected by portions of training regions without spectroscopy data - need to redefine those regions to exclude\n",
    "those parts\n",
    "\"\"\"\n",
    "\n",
    "statsfile = f'{analysis_path}{run_id}_train_sets.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    gb_train_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    gb_train_stats['XGB classified'] = stats.raster_stats(model_dir, map_kind=f'gb_class_{run_id}',\\\n",
    "                                                          regions=training_sets, resolution='lores_')\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(gb_train_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        gb_train_stats = json.load(f)\n",
    "        \n",
    "stats.plot_raster_stats(gb_train_stats, plot_file=f'{run_id}_train_stats.png')\n",
    "stats.display_raster_stats(gb_train_stats['XGB classified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bad55-63f7-41e3-94e7-067baf0bf616",
   "metadata": {},
   "source": [
    "### Run 2 - brightness normalization, different training set\n",
    "\n",
    "Are the maps different enough to be potentially useful in an ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defab103-443d-491e-a6fd-415fe28cc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define how this run will be executed\n",
    "\"\"\"\n",
    "\n",
    "#TODO: these should be class attributes?\n",
    "run_id = 'run2'\n",
    "brightness_norm = True\n",
    "n_iter = 10\n",
    "\n",
    "training_sets = {'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea'}\n",
    "\n",
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'SKona_B': 'SKona_TestB',\\\n",
    "                       'HBLower': 'HBLower',\\\n",
    "                       'SKona_A': 'SKona_TestA',\\\n",
    "                       'KonaMauka': 'KonaMauka',\\\n",
    "                       'CCTrees': 'tile024_10000_4375'}\n",
    "\n",
    "all_labelled_data = {**training_sets, **test_sets}\n",
    "\n",
    "\n",
    "utils = performance.Utils(all_labelled_data)\n",
    "\n",
    "manips = performance.MapManips(model_output_root=base_path,\\\n",
    "                               all_labelled_data=all_labelled_data)\n",
    "\n",
    "evalz = performance.Evaluate(model_output_root=base_path, training_sets=training_sets,\\\n",
    "                             all_labelled_data=all_labelled_data)\n",
    "\n",
    "stats = performance.Stats(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                          all_labelled_data=all_labelled_data,\\\n",
    "                          analysis_path=analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9459a4-eff4-44a6-a04c-5175030eaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing = False\n",
    "\n",
    "if use_existing:\n",
    "\n",
    "    with open(f'{model_dir}X_{run_id}.pkl', \"rb\") as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(f'{model_dir}y_{run_id}.pkl', \"rb\") as f:\n",
    "        y = pickle.load(f)\n",
    "else:\n",
    "    X, y = evalz.get_vars_from_rasters(xvars=xvars, bad_bands=bad_bands, mask_shade=True,\\\n",
    "                                       bnorm=brightness_norm, model_dir=model_dir, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c55b1-28fc-4040-a59c-e9022de5b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing = False\n",
    "\n",
    "gb_file = f'{model_dir}gb_{run_id}.pkl'\n",
    "\n",
    "if use_existing:\n",
    "    with open(gb_file, \"rb\") as f:\n",
    "        gb = pickle.load(f)\n",
    "else:\n",
    "    gb = evalz.ml_classify(X, y, n_iter=n_iter, scoring='recall', save_to=gb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcf012-89e8-474f-ac9c-e8580ca2804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_file = f'{model_dir}train_test_{run_id}.pkl'\n",
    "shap_file = f'/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/for_figures/shap_{run_id}.pkl'\n",
    "evalz.ml_metrics(gb, xvars, xy_file=train_test_file save_to=shap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba27840-a2d1-448f-9715-a19044f06830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "out_prefix = f'{base_path}ensembles/gb_prob_{run_id}'\n",
    "manips.gb_prob_to_raster(gb, xvars=xvars, bad_bands=bad_bands, out_prefix=out_prefix,\\\n",
    "                                   model_dir=model_dir, bnorm=brightness_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ee0e7-1e3d-4f54-99ce-00bd03a3afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    applied_model = f'{base_path}ensembles/gb_prob_{run_id}_{region}.tif'\n",
    "    outfile = f'{base_path}ensembles/gb_class_{run_id}_{region}.tif'\n",
    "    manips.probabilities_to_classes(applied_model, outfile, 0.2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9678f26-33eb-4043-a6a9-abcccd4c9241",
   "metadata": {},
   "source": [
    "### Run 3: repeat run 1 without brightness normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df80eb-cc6e-4b49-b715-8bbf0ff889a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'run3'\n",
    "brightness_norm = False\n",
    "n_iter = 10\n",
    "\n",
    "training_sets = {'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea',\\\n",
    "                           'HBLower': 'HBLower',\\\n",
    "                           'SKona_A': 'SKona_TestA',\\\n",
    "                           'KonaMauka': 'KonaMauka',\\\n",
    "                           'CCTrees': 'tile024_10000_4375'}\n",
    "\n",
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'SKona_B': 'SKona_TestB'}\n",
    "\n",
    "all_labelled_data = {**training_sets, **test_sets}\n",
    "\n",
    "utils = performance.Utils(all_labelled_data)\n",
    "\n",
    "manips = performance.MapManips(model_output_root=base_path,\\\n",
    "                               all_labelled_data=all_labelled_data)\n",
    "\n",
    "evalz = performance.Evaluate(model_output_root=base_path, training_sets=training_sets,\\\n",
    "                             all_labelled_data=all_labelled_data)\n",
    "\n",
    "stats = performance.Stats(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                          all_labelled_data=all_labelled_data,\\\n",
    "                          analysis_path=analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b6cb5-0492-4a1c-944f-bca14faf6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing = True\n",
    "\n",
    "if use_existing:\n",
    "\n",
    "    with open(f'{model_dir}X_{run_id}.pkl', \"rb\") as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(f'{model_dir}y_{run_id}.pkl', \"rb\") as f:\n",
    "        y = pickle.load(f)\n",
    "else:\n",
    "    X, y = evalz.get_vars_from_rasters(xvars=xvars, bad_bands=bad_bands, mask_shade=True,\\\n",
    "                                       bnorm=brightness_norm, model_dir=model_dir, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94330bd0-5d90-47fc-8699-30efa6a444e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing = True  \n",
    "\n",
    "gb_file = f'{model_dir}gb_{run_id}.pkl'\n",
    "\n",
    "if use_existing:\n",
    "    with open(gb_file, \"rb\") as f:\n",
    "        gb = pickle.load(f)\n",
    "else:\n",
    "    gb = evalz.ml_classify(X, y, n_iter=n_iter, scoring='recall', save_to=gb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7864968-6bb7-450d-b4f7-52a9b6f2e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_file = f'{model_dir}train_test_{run_id}.pkl'\n",
    "shap_file = f'/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/for_figures/shap_{run_id}.pkl'\n",
    "evalz.ml_metrics(gb, xvars, xy_file=train_test_file, save_to=shap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3ba1e-a373-467c-b09e-bfc65c0acde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "out_prefix = f'{base_path}ensembles/gb_prob_{run_id}'\n",
    "manips.gb_prob_to_raster(gb, xvars=xvars, bad_bands=bad_bands, out_prefix=out_prefix,\\\n",
    "                                   model_dir=model_dir, bnorm=brightness_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f2c9a-3539-4887-8d24-3c302918c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    applied_model = f'{base_path}ensembles/gb_prob_{run_id}_{region}.tif'\n",
    "    outfile = f'{base_path}ensembles/gb_class_{run_id}_{region}.tif'\n",
    "    manips.probabilities_to_classes(applied_model, outfile, 0.2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacee53f-8e8a-46a4-b9d1-ea86ef24ac56",
   "metadata": {},
   "source": [
    "### Run 4: as for run 2, but without brightness norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b6640-1073-4ae4-8200-6254a4f0407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'run4'\n",
    "brightness_norm = False\n",
    "n_iter = 10\n",
    "\n",
    "training_sets = {'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea'}\n",
    "\n",
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HBLower': 'HBLower',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'SKona_B': 'SKona_TestB',\\\n",
    "                       'SKona_A': 'SKona_TestA',\\\n",
    "                       'KonaMauka': 'KonaMauka',\\\n",
    "                       'CCTrees': 'tile024_10000_4375'}\n",
    "\n",
    "all_labelled_data = {**training_sets, **test_sets}\n",
    "\n",
    "utils = performance.Utils(all_labelled_data)\n",
    "\n",
    "manips = performance.MapManips(model_output_root=base_path,\\\n",
    "                               all_labelled_data=all_labelled_data)\n",
    "\n",
    "evalz = performance.Evaluate(model_output_root=base_path, training_sets=training_sets,\\\n",
    "                             all_labelled_data=all_labelled_data)\n",
    "\n",
    "stats = performance.Stats(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                          all_labelled_data=all_labelled_data,\\\n",
    "                          analysis_path=analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7e46e-f277-4458-a131-68b9c8258fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing = False\n",
    "\n",
    "if use_existing:\n",
    "\n",
    "    with open(f'{model_dir}X_{run_id}.pkl', \"rb\") as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(f'{model_dir}y_{run_id}.pkl', \"rb\") as f:\n",
    "        y = pickle.load(f)\n",
    "else:\n",
    "    X, y = evalz.get_vars_from_rasters(xvars=xvars, bad_bands=bad_bands, mask_shade=True,\\\n",
    "                                       bnorm=brightness_norm, model_dir=model_dir, run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9424a0e-a58f-4f09-ad88-bcef6f6eb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_existing = False\n",
    "\n",
    "gb_file = f'{model_dir}gb_{run_id}.pkl'\n",
    "\n",
    "if use_existing:\n",
    "    with open(gb_file, \"rb\") as f:\n",
    "        gb = pickle.load(f)\n",
    "else:\n",
    "    gb = evalz.ml_classify(X, y, n_iter=n_iter, scoring='recall', save_to=gb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b580e-d3f7-4b72-9251-f8a48a5bb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_file = f'{model_dir}train_test_{run_id}.pkl'\n",
    "shap_file = f'/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/for_figures/shap_{run_id}.pkl'\n",
    "evalz.ml_metrics(gb, xvars, xy_file=train_test_file, save_to=shap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375dd5b-60e2-4df9-af9d-0e7cc6aba342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "out_prefix = f'{base_path}ensembles/gb_prob_{run_id}'\n",
    "manips.gb_prob_to_raster(gb, xvars=xvars, bad_bands=bad_bands, out_prefix=out_prefix,\\\n",
    "                                   model_dir=model_dir, bnorm=brightness_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092f7c5-b9e5-4010-ada3-32fe1848f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    applied_model = f'{base_path}ensembles/gb_prob_{run_id}_{region}.tif'\n",
    "    outfile = f'{base_path}ensembles/gb_class_{run_id}_{region}.tif'\n",
    "    manips.probabilities_to_classes(applied_model, outfile, 0.2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585402b0-4c91-4439-ba81-5807d2c611bd",
   "metadata": {},
   "source": [
    "## Create ensemble GB probability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5eea94-fbd6-4b6c-99d6-889351fb9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Redefine test and training sets so we are sure to be always working with the same ones in this section\n",
    " - using the training and test sets from run 1\n",
    "\"\"\"\n",
    "\n",
    "training_sets = {'HOVE1': 'tile031_3125_11250',\\\n",
    "                           'CC1': 'tile024_10000_3125',\\\n",
    "                           'MIL1': 'tile030_10000_5625',\\\n",
    "                           'Hamakua': 'tile016_0_4375',\\\n",
    "                           'KParadise': 'KParadise',\\\n",
    "                           'WAI1': 'Waikoloa1',\\\n",
    "                           'KK1': 'Kukio1',\\\n",
    "                           'Waimea': 'Waimea',\\\n",
    "                           'HBLower': 'HBLower',\\\n",
    "                           'SKona_A': 'SKona_TestA',\\\n",
    "                           'KonaMauka': 'KonaMauka',\\\n",
    "                           'CCTrees': 'tile024_10000_4375'}\n",
    "\n",
    "test_sets = {'HBTest': 'HBTest',\\\n",
    "                       'HOVE2': 'tile031_2500_11250',\\\n",
    "                       'MIL2': 'tile030_9375_5625',\\\n",
    "                       'CC2': 'tile024_10000_2500',\\\n",
    "                       'Hamakua_A': 'Hamakua_testA',\\\n",
    "                       'Puako': 'Puako',\\\n",
    "                       'SKona_B': 'SKona_TestB'}\n",
    "\n",
    "all_labelled_data = {**training_sets, **test_sets}\n",
    "\n",
    "evalz = performance.Evaluate(model_output_root=base_path, training_sets=training_sets,\\\n",
    "                             all_labelled_data=all_labelled_data)\n",
    "\n",
    "stats = performance.Stats(model_output_root=base_path, test_sets=test_sets,\\\n",
    "                          all_labelled_data=all_labelled_data,\\\n",
    "                          analysis_path=analysis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81c321-3409-4d0e-83b9-a084abc581e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    ensemble.average_probabilities(model_nums=[1, 2, 3, 4], model_kind='GB', region=region, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916f22e-bb10-4e32-8070-937af5b16180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Probability histogram\n",
    "\"\"\"\n",
    "evalz.probability_hist(model_dir, 'gb_ensemble_prob', threshold=None, title='XGB Maps', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f121d-5f21-402b-b14b-97c36a2eaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalz.probability_hist(model_dir, 'lores_model', threshold=None, title='CNN Maps', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32455d-c66b-49ed-974a-6248a1c41c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    applied_model = f'{base_path}ensembles/gb_ensemble_prob_{region}.tif'\n",
    "    outfile = f'{base_path}ensembles/gb_ensemble_class_{region}.tif'\n",
    "    manips.probabilities_to_classes(applied_model, outfile, 0.2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa8128-b510-47f4-9422-2f054f1fe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "My stats for the TRAINING set. Presumably these should be very similar to those given by ml metrics -\n",
    "although those are for individual runs, not the ensemble.\n",
    "\"\"\"\n",
    "\n",
    "statsfile = f'{analysis_path}ensemble_train_sets.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    gb_train_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    gb_train_stats['XGB ensemble'] = stats.raster_stats(model_dir, map_kind=f'gb_ensemble_class',\\\n",
    "                                                          regions=training_sets, resolution='lores_')\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(gb_train_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        gb_train_stats = json.load(f)\n",
    "        \n",
    "stats.plot_raster_stats(gb_train_stats, plot_file=f'ensemble_train_stats.png')\n",
    "stats.display_raster_stats(gb_train_stats['XGB ensemble'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61ccfc-f399-4a94-99d3-4904ffb15842",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "My stats for the TEST set.\n",
    "\"\"\"\n",
    "\n",
    "statsfile = f'{analysis_path}ensemble_test_sets.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    gb_test_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    gb_test_stats['XGB ensemble'] = stats.raster_stats(model_dir, map_kind=f'gb_ensemble_class',\\\n",
    "                                                          regions=test_sets, resolution='lores_')\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(gb_test_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        gb_test_stats = json.load(f)\n",
    "        \n",
    "stats.plot_raster_stats(gb_test_stats, plot_file=f'ensemble_test_stats.png')\n",
    "stats.display_raster_stats(gb_test_stats['XGB ensemble'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d8ab9-b6c2-4e8a-9671-53d24add75bd",
   "metadata": {},
   "source": [
    "## Vectorize and 'clean' the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d565a60-d355-4502-b2d4-67581b5aa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping (files exist)\n",
    "#%%time\n",
    "\n",
    "for region in all_labelled_data.keys():\n",
    "    map_file = f'{base_path}ensembles/gb_ensemble_class_{region}.tif'\n",
    "    out_file = f'{base_path}ensembles/gb_ensemble_poly_{region}.tif'\n",
    "    manips.vectorize_and_clean(map_file, out_file, buffers=[-1, 0, 0], minpix=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b91ef5-60bd-44a1-b2e1-971fccd4701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "statsfile = f'{analysis_path}vec_train.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    vec_train_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    vec_train_stats['poly cleaned'] = stats.raster_stats(model_dir, map_kind=f'gb_ensemble_bounds',\\\n",
    "                                                         regions=training_sets, resolution='lores_')\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(vec_train_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        vec_train_stats = json.load(f)\n",
    "        \n",
    "stats.plot_raster_stats(vec_train_stats, plot_file='vec_train_stats.png')\n",
    "stats.display_raster_stats(vec_train_stats['poly cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b2858-de90-406c-8e00-8759b9be6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "statsfile = f'{analysis_path}vec_test.json'\n",
    "\n",
    "use_existing = False\n",
    "\n",
    "if use_existing is False:\n",
    "    vec_test_stats = {}\n",
    "    model_dir = f'{base_path}ensembles/'\n",
    "    vec_test_stats['poly cleaned'] = stats.raster_stats(model_dir, map_kind=f'gb_ensemble_bounds',\\\n",
    "                                                        regions=test_sets, resolution='lores_')\n",
    "    with open(statsfile.replace('tif', 'json'), \"w\") as f:\n",
    "        json.dump(vec_test_stats, f)\n",
    "\n",
    "else:\n",
    "    with open(statsfile) as f:\n",
    "        vec_test_stats = json.load(f)\n",
    "        \n",
    "stats.plot_raster_stats(vec_test_stats, plot_file='vec_test_stats.png')\n",
    "stats.display_raster_stats(vec_test_stats['poly cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce6a80-e3e4-4504-a5ed-aa61bda093ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "No bounding boxes\n",
    "\"\"\"\n",
    "\n",
    "stats.match_buildings_to_labels(model_dir, map_kind='gb_ensemble_poly')\n",
    "stats.vector_stats(model_dir, map_kind='gb_ensemble_poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68227c8b-51e7-4311-b621-f3cfde4310fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stats.building_size_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837f038-2ed9-48f4-a165-0556b7fecf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "With bounding boxes\n",
    "\"\"\"\n",
    "\n",
    "stats.match_buildings_to_labels(model_dir, map_kind='gb_ensemble_bounds')\n",
    "stats.vector_stats(model_dir, map_kind='gb_ensemble_bounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f49688-5ff0-450c-a1d8-57009a407c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stats.building_size_plots(sep=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e092fcd-d60f-49c8-9c6f-7452c53707d8",
   "metadata": {},
   "source": [
    "## Apply to whole tiles\n",
    "\n",
    "This should really be a separate notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a1cb31-2644-4fad-8911-4e416cc75168",
   "metadata": {},
   "outputs": [],
   "source": [
    "manips = performance.MapManips(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799ff4c-8298-4c03-aed7-e65d6fab0207",
   "metadata": {},
   "source": [
    "### South Kona region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e402c1-ad2b-4a77-97a1-a02ebbb1caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = ['024', '025', '030', '031']\n",
    "boundary_file = f'SKona_epsg32605_buf.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47ed67-f352-403b-87a4-4f3215a3cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping (files exist)\n",
    "#%%time 15 mins or so\n",
    "\"\"\"\n",
    "Create mean CNN maps and interpolate them to 2m pixel size\n",
    "\"\"\"\n",
    "\n",
    "for tile in tiles:\n",
    "    apply.cnn_average_interpolate(tile=tile, combos=list(range(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1193f-b11b-4b1b-be7b-9de1ef70b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping (files exist)\n",
    "#%%time\n",
    "\"\"\"\n",
    "Apply the saved XGB models to the reflectance, interpolated mean CNN map, and canopy height map for each tile\n",
    "\"\"\"\n",
    "\n",
    "for tile in tiles:\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run1.pkl', bnorm=True)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run2.pkl', bnorm=True)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run3.pkl', bnorm=False)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run4.pkl', bnorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c29930-0397-4cd5-966e-73e3303b856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile024.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile025.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile030.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile031.tif\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Average the four runs and convert probabilities to classes\n",
    "\"\"\"\n",
    "\n",
    "for tile in tiles:\n",
    "    apply.xgb_ensemble_classes(tile, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12163cf7-803c-45d4-a33d-61a94f70511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- cropping to study region boundaries\n",
      "Saving /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/SKona_xgb_mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mosaic the classmap tiles and crop to the study region boundary\n",
    "\"\"\"\n",
    "\n",
    "boundary_file = f'SKona_epsg32605_buf.shp'\n",
    "apply.mosaic_and_crop(tiles, boundary_file=boundary_file, region='SKona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc9dd11-90d6-4226-b810-3c4826a6824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/SKona_xgb_mosaic.tif\n",
      "  - Removing polygons that intersect with roads\n",
      "  - Removing polygons outside/overlapping the coast\n",
      "CPU times: user 6min 6s, sys: 13.9 s, total: 6min 20s\n",
      "Wall time: 6min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Carry out the vector cleaning ops\n",
    "\"\"\"\n",
    "\n",
    "map_file = f'{base_path}ensembles/SKona_xgb_mosaic.tif'\n",
    "out_file = f'{base_path}ensembles/SKona_poly.tif'\n",
    "manips.vectorize_and_clean(map_file, out_file, buffers=[-1, 0, 0], minpix=25, mask_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185b2b0b-0df5-4bb0-b9d3-51e0314e0b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/final_maps/SKona.tif.aux.xml'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copy the final map to the final_maps directory and give it a better name\n",
    "\"\"\"\n",
    "\n",
    "src = f'{base_path}ensembles/SKona_bounds.tif'\n",
    "dst = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/final_maps/SKona.tif'\n",
    "shutil.copyfile(src, dst)\n",
    "shutil.copyfile(src.replace('.tif', '.hdr'), dst.replace('.tif', '.hdr'))\n",
    "#shutil.copyfile(src, dst+'.aux.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f951691-b103-4d6c-9173-83823f7a9261",
   "metadata": {},
   "source": [
    "### North Hilo-Hamakua region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bf1eae-047f-4966-96bd-5f13aa78454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = ['008', '009', '014', '015', '016', '021', '022']\n",
    "boundary_file = f'NHiloHamakua_epsg32605.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de4e467-6eea-4db7-8b18-f1d35ae3cf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping (files exist)\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping (files exist)\n",
    "\n",
    "for tile in tiles:\n",
    "    apply.cnn_average_interpolate(tile=tile, combos=list(range(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51b870f-f7a7-4db0-8922-7f04bd872839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping (files exist)\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping (files exist)\n",
    "%%time\n",
    "\n",
    "for tile in tiles:\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run1.pkl', bnorm=True)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run2.pkl', bnorm=True)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run3.pkl', bnorm=False)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run4.pkl', bnorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb52142-f329-40f4-83c5-6153a65f117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile008.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile009.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile014.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile015.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile016.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile021.tif\n",
      "Creating mean XGB map\n",
      "Writing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/xgb_class_tile022.tif\n"
     ]
    }
   ],
   "source": [
    "for tile in tiles:\n",
    "    apply.xgb_ensemble_classes(tile, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc21c7c-500f-4ab0-8d61-335d8d80de52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- cropping to study region boundaries\n",
      "Saving /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/NHiloHamakua_xgb_mosaic.tif\n"
     ]
    }
   ],
   "source": [
    "apply.mosaic_and_crop(tiles, boundary_file=boundary_file, region='NHiloHamakua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa06632-9a2e-47e9-b588-f00f8c8858e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing /data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/bfgn_output_buildings2/model_runs/ensembles/NHiloHamakua_xgb_mosaic.tif\n",
      "  - Removing polygons that intersect with roads\n",
      "  - Removing polygons outside/overlapping the coast\n"
     ]
    }
   ],
   "source": [
    "map_file = f'{base_path}ensembles/NHiloHamakua_xgb_mosaic.tif'\n",
    "out_file = f'{base_path}ensembles/NHiloHamakua_poly.tif'\n",
    "manips.vectorize_and_clean(map_file, out_file, buffers=[-1, 0, 0], minpix=25, mask_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda4cc75-b949-4e7c-b2bb-d1404500c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/final_maps/NHiloHamakua.tif.aux.xml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = f'{base_path}ensembles/NHiloHamakua_bounds.tif'\n",
    "dst = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/final_maps/NHiloHamakua.tif'\n",
    "shutil.copyfile(src, dst)\n",
    "shutil.copyfile(src.replace('.tif', '.hdr'), dst.replace('.tif', '.hdr'))\n",
    "shutil.copyfile(src+'.aux.xml', dst+'.aux.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335b7d4-992f-4ffa-a177-f32a5733acc5",
   "metadata": {},
   "source": [
    "### N. Kona - S. Kohala region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e45bcd7-ad55-4c6b-8188-101435b98e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = ['007', '012', '013', '018', '019', '020']\n",
    "boundary_file = f'NKonaSKohala_epsg32605_buf.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96116a2e-88e2-4096-8e55-b251bb36b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping (files exist)\n",
    "for tile in tiles:\n",
    "    apply.cnn_average_interpolate(tile=tile, combos=list(range(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85231830-276e-4f21-8990-a754d9837ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Window(col_off=0, row_off=0, width=12500, height=500)\n",
      "1 Window(col_off=0, row_off=500, width=12500, height=500)\n",
      "2 Window(col_off=0, row_off=1000, width=12500, height=500)\n",
      "3 Window(col_off=0, row_off=1500, width=12500, height=500)\n",
      "4 Window(col_off=0, row_off=2000, width=12500, height=500)\n",
      "5 Window(col_off=0, row_off=2500, width=12500, height=500)\n",
      "6 Window(col_off=0, row_off=3000, width=12500, height=500)\n",
      "7 Window(col_off=0, row_off=3500, width=12500, height=500)\n",
      "8 Window(col_off=0, row_off=4000, width=12500, height=500)\n",
      "9 Window(col_off=0, row_off=4500, width=12500, height=500)\n",
      "10 Window(col_off=0, row_off=5000, width=12500, height=500)\n",
      "11 Window(col_off=0, row_off=5500, width=12500, height=500)\n",
      "12 Window(col_off=0, row_off=6000, width=12500, height=500)\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping (files exist)\n",
    "%%time\n",
    "\n",
    "for tile in tiles:\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run1.pkl', bnorm=True)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run2.pkl', bnorm=True)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run3.pkl', bnorm=False)\n",
    "    apply.loop_over_windows(tile=tile, bad_bands=bad_bands, model='gb_run4.pkl', bnorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca45c1c-3075-4f75-a9a4-9fa906f04102",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile in tiles:\n",
    "    apply.xgb_ensemble_classes(tile, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6220bd6-7ba8-4d09-8a4d-09f64a8e22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this region also contains tiles 8 and 14, which were prepared earlier (they're also in Hilo-Hamakua)\n",
    "tiles = ['007', '008', '012', '013', '014', '018', '019', '020'] \n",
    "apply.mosaic_and_crop(tiles, boundary_file=boundary_file, region='NKonaSKohala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4c916-1847-4d49-a75b-2365ad23102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_file = f'{base_path}ensembles/NKonaSKohala_xgb_mosaic.tif'\n",
    "out_file = f'{base_path}ensembles/NKonaSKohala_poly.tif'\n",
    "manips.vectorize_and_clean(map_file, out_file, buffers=[-1, 0, 0], minpix=25, mask_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199fe2e-9300-4ce6-a0e4-6aa130b99760",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f'{base_path}ensembles/NKonaSKohala_bounds.tif'\n",
    "dst = '/data/gdcsdata/HawaiiMapping/ProjectFiles/Rachel/final_maps/NKonaSKohala.tif'\n",
    "shutil.copyfile(src, dst)\n",
    "shutil.copyfile(src.replace('.tif', '.hdr'), dst.replace('.tif', '.hdr'))\n",
    "shutil.copyfile(src+'.aux.xml', dst+'.aux.xml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost",
   "language": "python",
   "name": "xgboost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
